{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53897189",
   "metadata": {},
   "source": [
    "### 1. Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77dad5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import category_encoders as ce\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30a6ae",
   "metadata": {},
   "source": [
    "### 2. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c3ff45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP DAY_TYPE  \\\n",
       "0      T1         B          NaN          15.0  20000542  1408039037        A   \n",
       "1      T2         B          NaN          57.0  20000108  1408038611        A   \n",
       "2      T3         B          NaN          15.0  20000370  1408038568        A   \n",
       "3      T4         B          NaN          53.0  20000492  1408039090        A   \n",
       "4      T5         B          NaN          18.0  20000621  1408039177        A   \n",
       "\n",
       "   MISSING_DATA  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../test/test_public.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5266f438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net A\n",
    "def _weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class Net_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)  # New layer: fc5 -> fc6\n",
    "        self.fc6 = nn.Linear(64, 32)   # New layer: fc6 -> fc7\n",
    "        self.fc7 = nn.Linear(32, 1)    # New layer: fc7 -> output\n",
    "        self.apply(_weight_init)\n",
    "        self.apply(_weight_init) # 初始化参数\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "net_A = Net_A()\n",
    "net_A.load_state_dict(torch.load('../model/modelA.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f268bd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net B\n",
    "class Net_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(95, 256)\n",
    "        self.fc2 = nn.Linear(256,256)\n",
    "        self.fc3 = nn.Linear(256,256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.apply(_weight_init) # 初始化参数\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "net_B = Net_B()\n",
    "net_B.load_state_dict(torch.load('../model/modelB.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a97d68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net C\n",
    "class Net_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(17, 512)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512,512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 1)\n",
    "        self.apply(_weight_init) # 初始化参数\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "net_C = Net_C()\n",
    "net_C.load_state_dict(torch.load('../model/modelC.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c9e1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_test = df_test.drop(columns=[ 'TAXI_ID', 'TIMESTAMP', 'MISSING_DATA', 'YR',\n",
    "#                                 'DAY'])\n",
    "\n",
    "# df_test['MON'] = df_test['MON'].astype(str)\n",
    "# df_test['WK'] = df_test['WK'].astype(str)\n",
    "# df_test['HR'] = df_test['HR'].astype(str)\n",
    "\n",
    "# dummy_test = pd.get_dummies(df_test[['MON', 'WK', 'HR']])\n",
    "# df_test = pd.concat([df_test, dummy_test], axis=1)\n",
    "\n",
    "# # test_wk = df_test[df_test[\"WK\"] == 7]\n",
    "# # print(test_wk)\n",
    "# df_test = df_test.drop(columns=['MON', 'WK', 'HR'])\n",
    "\n",
    "# df_test['MON_1'] = 0\n",
    "# df_test['MON_2'] = 0\n",
    "# df_test['MON_3'] = 0\n",
    "# df_test['MON_4'] = 0\n",
    "# df_test['MON_5'] = 0\n",
    "# df_test['MON_6'] = 0\n",
    "# df_test['MON_7'] = 0\n",
    "\n",
    "# df_test['WK_2'] = 0\n",
    "# df_test['WK_4'] = 0\n",
    "\n",
    "# df_test['HR_0'] = 0\n",
    "# df_test['HR_1'] = 0\n",
    "# df_test['HR_4'] = 0\n",
    "# df_test['HR_5'] = 0\n",
    "# df_test['HR_9'] = 0\n",
    "# df_test['HR_10'] = 0\n",
    "# df_test['HR_18'] = 0\n",
    "# df_test['HR_19'] = 0\n",
    "# df_test['HR_20'] = 0\n",
    "# df_test['HR_21'] = 0\n",
    "# df_test['HR_22'] = 0\n",
    "# df_test['HR_23'] = 0\n",
    "\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     if row[\"CALL_TYPE\"] == \"A\":\n",
    "#         print(row[\"TRIP_ID\"])\n",
    "\n",
    "# for index, row in df_test.iterrows():\n",
    "#     if row[\"CALL_TYPE\"] == \"A\":\n",
    "#         df_test['Unique_TAXI_ID'].iloc[index] = (df_test['Unique_TAXI_ID'].iloc[index] - 333.4006168270417) / 209.67678198094498\n",
    "#         df_test['ORIGIN_CALL'].iloc[index] = (df_test['ORIGIN_CALL'].iloc[index] - 24490.363017792035) / 19624.29004302366\n",
    "#     elif row[\"CALL_TYPE\"] == \"B\":\n",
    "#         df_test['Unique_TAXI_ID'].iloc[index] = (df_test['Unique_TAXI_ID'].iloc[index] - 346.12949952304933) / 210.39338583617038\n",
    "#         df_test['ORIGIN_STAND'].iloc[index] = (df_test['ORIGIN_STAND'].iloc[index] - 30.2782090247832) / 17.743860394485583\n",
    "#     elif row[\"CALL_TYPE\"] == \"C\":\n",
    "#         df_test['Unique_TAXI_ID'].iloc[index] = (df_test['Unique_TAXI_ID'].iloc[index] - 362.4130874078395) / 212.65140390214862\n",
    "\n",
    "# # cols = list(df_test.columns.values)\n",
    "# # print(cols)\n",
    "\n",
    "# print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ed0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_time(x):\n",
    "  # We are using python's builtin datetime library\n",
    "  # https://docs.python.org/3/library/datetime.html#datetime.date.fromtimestamp\n",
    "\n",
    "  # Each x is essentially a 1 row, 1 column pandas Series\n",
    "  dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "  return dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "\n",
    "def parse_TAXI_ID(x):\n",
    "    return (x % pow(10,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121edf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>YR</th>\n",
       "      <th>MON</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HR</th>\n",
       "      <th>WK</th>\n",
       "      <th>Unique_TAXI_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA    YR  MON  DAY  HR  WK  Unique_TAXI_ID  \n",
       "0          A         False  2014    8   14  17   3             542  \n",
       "1          A         False  2014    8   14  17   3             108  \n",
       "2          A         False  2014    8   14  17   3             370  \n",
       "3          A         False  2014    8   14  17   3             492  \n",
       "4          A         False  2014    8   14  17   3             621  \n",
       "..       ...           ...   ...  ...  ...  ..  ..             ...  \n",
       "315        A         False  2014   12   21  14   6             430  \n",
       "316        A         False  2014   12   21  14   6              20  \n",
       "317        A         False  2014   12   21  14   6             207  \n",
       "318        A         False  2014   12   21  14   6             667  \n",
       "319        A         False  2014   12   21  14   6             255  \n",
       "\n",
       "[320 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../test/test_public.csv\")\n",
    "\n",
    "df_test[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_test[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "\n",
    "df_test[\"Unique_TAXI_ID\"] = df_test[\"TAXI_ID\"].apply(parse_TAXI_ID)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a55029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(call_type, test_set, net):\n",
    "    \n",
    "    if call_type == \"A\":\n",
    "        \n",
    "        required_cols = ['ORIGIN_CALL_0', 'ORIGIN_CALL_1', 'ORIGIN_CALL_2', \n",
    "                         'ORIGIN_CALL_3', 'ORIGIN_CALL_4', 'ORIGIN_CALL_5', \n",
    "                         'ORIGIN_CALL_6', 'ORIGIN_CALL_7', 'ORIGIN_CALL_8', \n",
    "                         'ORIGIN_CALL_9', 'ORIGIN_CALL_10', 'ORIGIN_CALL_11', \n",
    "                         'ORIGIN_CALL_12', 'ORIGIN_CALL_13', 'ORIGIN_CALL_14', \n",
    "                         'ORIGIN_CALL_15', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', \n",
    "                         'WK_0', 'WK_1', 'WK_2']\n",
    "        \n",
    "        all_features = pd.DataFrame(columns=required_cols)\n",
    "        df_tr_test = test_set\n",
    "        \n",
    "#         print(df_tr_test)\n",
    "        \n",
    "        all_features_test = df_tr_test[[]]\n",
    "\n",
    "        # Create an instance of BinaryEncoder\n",
    "        binary_encoder_origin_test = ce.BinaryEncoder(cols=['ORIGIN_CALL'])\n",
    "        binary_encoder_hr_test = ce.BinaryEncoder(cols=['HR'])\n",
    "        binary_encoder_wk_test = ce.BinaryEncoder(cols=['WK'])\n",
    "\n",
    "\n",
    "        # Apply binary encoding to the 'ORIGIN_CALL' column\n",
    "        encoded_data_origin_test = binary_encoder_origin_test.fit_transform(df_tr_test['ORIGIN_CALL'])\n",
    "        encoded_data_hr_test = binary_encoder_hr_test.fit_transform(df_tr_test['HR'])\n",
    "        encoded_data_wk_test = binary_encoder_wk_test.fit_transform(df_tr_test['WK'])\n",
    "\n",
    "        # Concatenate the encoded data with the original DataFrame\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_origin_test], axis=1)\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_hr_test], axis=1)\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_wk_test], axis=1)\n",
    "\n",
    "        missing_columns = set(all_features.columns)-set(all_features_test.columns)\n",
    "\n",
    "        for column in missing_columns:\n",
    "            all_features_test[column] = 0\n",
    "\n",
    "        prediction = net(torch.tensor(all_features_test.values, dtype=torch.float))\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    elif call_type == \"B\":\n",
    "        \n",
    "        required_cols = ['ORIGIN_STAND_1.0', 'ORIGIN_STAND_10.0', 'ORIGIN_STAND_11.0', 'ORIGIN_STAND_12.0', \n",
    "                         'ORIGIN_STAND_13.0', 'ORIGIN_STAND_14.0', 'ORIGIN_STAND_15.0', 'ORIGIN_STAND_16.0', \n",
    "                         'ORIGIN_STAND_17.0', 'ORIGIN_STAND_18.0', 'ORIGIN_STAND_19.0', 'ORIGIN_STAND_2.0', \n",
    "                         'ORIGIN_STAND_20.0', 'ORIGIN_STAND_21.0', 'ORIGIN_STAND_22.0', 'ORIGIN_STAND_23.0', \n",
    "                         'ORIGIN_STAND_24.0', 'ORIGIN_STAND_25.0', 'ORIGIN_STAND_26.0', 'ORIGIN_STAND_27.0', \n",
    "                         'ORIGIN_STAND_28.0', 'ORIGIN_STAND_29.0', 'ORIGIN_STAND_3.0', 'ORIGIN_STAND_30.0', \n",
    "                         'ORIGIN_STAND_31.0', 'ORIGIN_STAND_32.0', 'ORIGIN_STAND_33.0', 'ORIGIN_STAND_34.0', \n",
    "                         'ORIGIN_STAND_35.0', 'ORIGIN_STAND_36.0', 'ORIGIN_STAND_37.0', 'ORIGIN_STAND_38.0', \n",
    "                         'ORIGIN_STAND_39.0', 'ORIGIN_STAND_4.0', 'ORIGIN_STAND_40.0', 'ORIGIN_STAND_41.0', \n",
    "                         'ORIGIN_STAND_42.0', 'ORIGIN_STAND_43.0', 'ORIGIN_STAND_44.0', 'ORIGIN_STAND_45.0', \n",
    "                         'ORIGIN_STAND_46.0', 'ORIGIN_STAND_47.0', 'ORIGIN_STAND_48.0', 'ORIGIN_STAND_49.0', \n",
    "                         'ORIGIN_STAND_5.0', 'ORIGIN_STAND_50.0', 'ORIGIN_STAND_51.0', 'ORIGIN_STAND_52.0', \n",
    "                         'ORIGIN_STAND_53.0', 'ORIGIN_STAND_54.0', 'ORIGIN_STAND_55.0', 'ORIGIN_STAND_56.0', \n",
    "                         'ORIGIN_STAND_57.0', 'ORIGIN_STAND_58.0', 'ORIGIN_STAND_59.0', 'ORIGIN_STAND_6.0', \n",
    "                         'ORIGIN_STAND_60.0', 'ORIGIN_STAND_61.0', 'ORIGIN_STAND_62.0', 'ORIGIN_STAND_63.0', \n",
    "                         'ORIGIN_STAND_7.0', 'ORIGIN_STAND_8.0', 'ORIGIN_STAND_9.0', 'ORIGIN_STAND_nan', 'WK_0', \n",
    "                         'WK_1', 'WK_2', 'WK_3', 'WK_4', 'WK_5', 'WK_6', 'HR_0', 'HR_1', 'HR_10', 'HR_11', 'HR_12', \n",
    "                         'HR_13', 'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_2', 'HR_20', 'HR_21', \n",
    "                         'HR_22', 'HR_23', 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7', 'HR_8', 'HR_9']\n",
    "        \n",
    "        all_features = pd.DataFrame(columns=required_cols)\n",
    "        df_tr_test = test_set\n",
    "        \n",
    "        all_features_test = df_tr_test[[\"ORIGIN_STAND\",\"WK\",\"HR\"]]\n",
    "\n",
    "        all_features_test[\"ORIGIN_STAND\"] = all_features_test[\"ORIGIN_STAND\"].astype(str)\n",
    "        all_features_test['WK'] = all_features_test['WK'].astype(str)\n",
    "        all_features_test['HR'] = all_features_test['HR'].astype(str)\n",
    "\n",
    "        all_features_test = pd.get_dummies(all_features_test)\n",
    "\n",
    "        missing_columns = set(all_features.columns)-set(all_features_test.columns)\n",
    "\n",
    "        for column in missing_columns:\n",
    "            all_features_test[column] = 0\n",
    "        \n",
    "        prediction = net(torch.tensor(all_features_test.values, dtype=torch.float))\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    elif call_type == \"C\":\n",
    "        required_cols = ['Unique_TAXI_ID_0', 'Unique_TAXI_ID_1', 'Unique_TAXI_ID_2', 'Unique_TAXI_ID_3', \n",
    "                         'Unique_TAXI_ID_4', 'Unique_TAXI_ID_5', 'Unique_TAXI_ID_6', 'Unique_TAXI_ID_7', \n",
    "                         'Unique_TAXI_ID_8', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'WK_0', 'WK_1', 'WK_2']\n",
    "        \n",
    "        all_features = pd.DataFrame(columns=required_cols)\n",
    "        df_tr_test = test_set\n",
    "    \n",
    "        all_features_test = df_tr_test[[]]\n",
    "\n",
    "        # Create an instance of BinaryEncoder\n",
    "        binary_encoder_id_test = ce.BinaryEncoder(cols=['Unique_TAXI_ID'])\n",
    "        binary_encoder_hr_test = ce.BinaryEncoder(cols=['HR'])\n",
    "        binary_encoder_wk_test = ce.BinaryEncoder(cols=['WK'])\n",
    "\n",
    "\n",
    "        # Apply binary encoding to the 'ORIGIN_CALL' column\n",
    "        encoded_data_id_test = binary_encoder_id_test.fit_transform(df_tr_test['Unique_TAXI_ID'])\n",
    "        encoded_data_hr_test = binary_encoder_hr_test.fit_transform(df_tr_test['HR'])\n",
    "        encoded_data_wk_test = binary_encoder_wk_test.fit_transform(df_tr_test['WK'])\n",
    "\n",
    "        # Concatenate the encoded data with the original DataFrame\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_id_test], axis=1)\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_hr_test], axis=1)\n",
    "        all_features_test = pd.concat([all_features_test, encoded_data_wk_test], axis=1)\n",
    "\n",
    "        missing_columns = set(all_features.columns)-set(all_features_test.columns)\n",
    "\n",
    "        for column in missing_columns:\n",
    "            all_features_test[column] = 0\n",
    "\n",
    "        prediction = net(torch.tensor(all_features_test.values, dtype=torch.float))\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Illegal Call Type!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6430a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109411/533806469.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_features_test[\"ORIGIN_STAND\"] = all_features_test[\"ORIGIN_STAND\"].astype(str)\n",
      "/tmp/ipykernel_109411/533806469.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_features_test['WK'] = all_features_test['WK'].astype(str)\n",
      "/tmp/ipykernel_109411/533806469.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_features_test['HR'] = all_features_test['HR'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T6': tensor([487.3210], grad_fn=<SelectBackward0>),\n",
       " 'T8': tensor([367.9285], grad_fn=<SelectBackward0>),\n",
       " 'T22': tensor([539.7828], grad_fn=<SelectBackward0>),\n",
       " 'T23': tensor([482.3542], grad_fn=<SelectBackward0>),\n",
       " 'T37': tensor([596.9558], grad_fn=<SelectBackward0>),\n",
       " 'T60': tensor([664.8036], grad_fn=<SelectBackward0>),\n",
       " 'T64': tensor([596.9558], grad_fn=<SelectBackward0>),\n",
       " 'T68': tensor([593.5859], grad_fn=<SelectBackward0>),\n",
       " 'T81': tensor([344.1285], grad_fn=<SelectBackward0>),\n",
       " 'T83': tensor([344.1285], grad_fn=<SelectBackward0>),\n",
       " 'T84': tensor([464.0434], grad_fn=<SelectBackward0>),\n",
       " 'T86': tensor([499.7385], grad_fn=<SelectBackward0>),\n",
       " 'T91': tensor([578.1052], grad_fn=<SelectBackward0>),\n",
       " 'T92': tensor([663.6332], grad_fn=<SelectBackward0>),\n",
       " 'T95': tensor([663.6332], grad_fn=<SelectBackward0>),\n",
       " 'T99': tensor([493.1104], grad_fn=<SelectBackward0>),\n",
       " 'T100': tensor([543.7289], grad_fn=<SelectBackward0>),\n",
       " 'T101': tensor([479.7131], grad_fn=<SelectBackward0>),\n",
       " 'T111': tensor([551.2966], grad_fn=<SelectBackward0>),\n",
       " 'T115': tensor([663.6332], grad_fn=<SelectBackward0>),\n",
       " 'T116': tensor([522.2129], grad_fn=<SelectBackward0>),\n",
       " 'T117': tensor([663.6332], grad_fn=<SelectBackward0>),\n",
       " 'T119': tensor([615.5483], grad_fn=<SelectBackward0>),\n",
       " 'T120': tensor([589.9185], grad_fn=<SelectBackward0>),\n",
       " 'T126': tensor([561.5974], grad_fn=<SelectBackward0>),\n",
       " 'T127': tensor([491.8844], grad_fn=<SelectBackward0>),\n",
       " 'T128': tensor([470.6112], grad_fn=<SelectBackward0>),\n",
       " 'T129': tensor([655.2149], grad_fn=<SelectBackward0>),\n",
       " 'T133': tensor([560.9080], grad_fn=<SelectBackward0>),\n",
       " 'T144': tensor([241.6486], grad_fn=<SelectBackward0>),\n",
       " 'T145': tensor([462.0470], grad_fn=<SelectBackward0>),\n",
       " 'T148': tensor([401.9682], grad_fn=<SelectBackward0>),\n",
       " 'T151': tensor([549.5228], grad_fn=<SelectBackward0>),\n",
       " 'T152': tensor([370.4224], grad_fn=<SelectBackward0>),\n",
       " 'T157': tensor([537.2764], grad_fn=<SelectBackward0>),\n",
       " 'T158': tensor([683.8836], grad_fn=<SelectBackward0>),\n",
       " 'T160': tensor([567.0612], grad_fn=<SelectBackward0>),\n",
       " 'T164': tensor([587.6258], grad_fn=<SelectBackward0>),\n",
       " 'T168': tensor([683.8836], grad_fn=<SelectBackward0>),\n",
       " 'T170': tensor([746.8156], grad_fn=<SelectBackward0>),\n",
       " 'T172': tensor([643.2775], grad_fn=<SelectBackward0>),\n",
       " 'T175': tensor([574.2369], grad_fn=<SelectBackward0>),\n",
       " 'T185': tensor([435.9083], grad_fn=<SelectBackward0>),\n",
       " 'T186': tensor([700.2869], grad_fn=<SelectBackward0>),\n",
       " 'T187': tensor([761.7469], grad_fn=<SelectBackward0>),\n",
       " 'T190': tensor([606.6907], grad_fn=<SelectBackward0>),\n",
       " 'T194': tensor([683.8836], grad_fn=<SelectBackward0>),\n",
       " 'T198': tensor([626.5048], grad_fn=<SelectBackward0>),\n",
       " 'T200': tensor([640.3105], grad_fn=<SelectBackward0>),\n",
       " 'T209': tensor([711.7291], grad_fn=<SelectBackward0>),\n",
       " 'T215': tensor([611.8837], grad_fn=<SelectBackward0>),\n",
       " 'T216': tensor([603.7352], grad_fn=<SelectBackward0>),\n",
       " 'T223': tensor([775.8401], grad_fn=<SelectBackward0>),\n",
       " 'T230': tensor([618.3427], grad_fn=<SelectBackward0>),\n",
       " 'T235': tensor([683.8836], grad_fn=<SelectBackward0>),\n",
       " 'T251': tensor([717.0219], grad_fn=<SelectBackward0>),\n",
       " 'T260': tensor([708.1254], grad_fn=<SelectBackward0>),\n",
       " 'T293': tensor([563.2405], grad_fn=<SelectBackward0>),\n",
       " 'T300': tensor([593.6241], grad_fn=<SelectBackward0>),\n",
       " 'T302': tensor([586.1791], grad_fn=<SelectBackward0>),\n",
       " 'T304': tensor([773.5577], grad_fn=<SelectBackward0>),\n",
       " 'T310': tensor([585.7895], grad_fn=<SelectBackward0>),\n",
       " 'T312': tensor([649.6045], grad_fn=<SelectBackward0>),\n",
       " 'T313': tensor([687.9167], grad_fn=<SelectBackward0>),\n",
       " 'T314': tensor([813.4287], grad_fn=<SelectBackward0>),\n",
       " 'T315': tensor([618.0929], grad_fn=<SelectBackward0>),\n",
       " 'T317': tensor([682.5587], grad_fn=<SelectBackward0>),\n",
       " 'T319': tensor([478.6146], grad_fn=<SelectBackward0>),\n",
       " 'T320': tensor([618.7448], grad_fn=<SelectBackward0>),\n",
       " 'T323': tensor([501.6548], grad_fn=<SelectBackward0>),\n",
       " 'T326': tensor([598.3981], grad_fn=<SelectBackward0>),\n",
       " 'T327': tensor([629.7758], grad_fn=<SelectBackward0>),\n",
       " 'T1': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T2': tensor([312.0147], grad_fn=<SelectBackward0>),\n",
       " 'T3': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T4': tensor([298.6975], grad_fn=<SelectBackward0>),\n",
       " 'T5': tensor([384.8015], grad_fn=<SelectBackward0>),\n",
       " 'T7': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T9': tensor([352.0876], grad_fn=<SelectBackward0>),\n",
       " 'T10': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T11': tensor([409.1562], grad_fn=<SelectBackward0>),\n",
       " 'T19': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T21': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T24': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T25': tensor([329.3804], grad_fn=<SelectBackward0>),\n",
       " 'T26': tensor([446.3248], grad_fn=<SelectBackward0>),\n",
       " 'T27': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T28': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T29': tensor([290.7635], grad_fn=<SelectBackward0>),\n",
       " 'T30': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T31': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T32': tensor([312.0147], grad_fn=<SelectBackward0>),\n",
       " 'T38': tensor([353.6065], grad_fn=<SelectBackward0>),\n",
       " 'T39': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T40': tensor([312.5316], grad_fn=<SelectBackward0>),\n",
       " 'T41': tensor([297.4413], grad_fn=<SelectBackward0>),\n",
       " 'T44': tensor([352.0876], grad_fn=<SelectBackward0>),\n",
       " 'T45': tensor([405.8394], grad_fn=<SelectBackward0>),\n",
       " 'T46': tensor([430.9528], grad_fn=<SelectBackward0>),\n",
       " 'T49': tensor([333.6329], grad_fn=<SelectBackward0>),\n",
       " 'T50': tensor([409.1562], grad_fn=<SelectBackward0>),\n",
       " 'T51': tensor([294.5285], grad_fn=<SelectBackward0>),\n",
       " 'T52': tensor([314.3465], grad_fn=<SelectBackward0>),\n",
       " 'T53': tensor([353.6065], grad_fn=<SelectBackward0>),\n",
       " 'T54': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T55': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T56': tensor([330.4405], grad_fn=<SelectBackward0>),\n",
       " 'T57': tensor([352.0876], grad_fn=<SelectBackward0>),\n",
       " 'T58': tensor([270.7758], grad_fn=<SelectBackward0>),\n",
       " 'T61': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T65': tensor([352.0876], grad_fn=<SelectBackward0>),\n",
       " 'T66': tensor([352.0876], grad_fn=<SelectBackward0>),\n",
       " 'T67': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T70': tensor([294.5285], grad_fn=<SelectBackward0>),\n",
       " 'T73': tensor([362.3256], grad_fn=<SelectBackward0>),\n",
       " 'T75': tensor([483.2951], grad_fn=<SelectBackward0>),\n",
       " 'T77': tensor([431.0171], grad_fn=<SelectBackward0>),\n",
       " 'T82': tensor([535.5089], grad_fn=<SelectBackward0>),\n",
       " 'T85': tensor([415.0822], grad_fn=<SelectBackward0>),\n",
       " 'T90': tensor([418.3273], grad_fn=<SelectBackward0>),\n",
       " 'T96': tensor([546.7880], grad_fn=<SelectBackward0>),\n",
       " 'T103': tensor([415.0822], grad_fn=<SelectBackward0>),\n",
       " 'T104': tensor([360.7118], grad_fn=<SelectBackward0>),\n",
       " 'T109': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T110': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T112': tensor([416.3099], grad_fn=<SelectBackward0>),\n",
       " 'T113': tensor([417.5914], grad_fn=<SelectBackward0>),\n",
       " 'T114': tensor([360.7118], grad_fn=<SelectBackward0>),\n",
       " 'T118': tensor([480.5116], grad_fn=<SelectBackward0>),\n",
       " 'T122': tensor([408.3044], grad_fn=<SelectBackward0>),\n",
       " 'T123': tensor([574.6146], grad_fn=<SelectBackward0>),\n",
       " 'T125': tensor([396.3597], grad_fn=<SelectBackward0>),\n",
       " 'T130': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T135': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T136': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T137': tensor([483.2951], grad_fn=<SelectBackward0>),\n",
       " 'T142': tensor([542.2172], grad_fn=<SelectBackward0>),\n",
       " 'T143': tensor([408.3044], grad_fn=<SelectBackward0>),\n",
       " 'T147': tensor([447.9985], grad_fn=<SelectBackward0>),\n",
       " 'T149': tensor([606.2863], grad_fn=<SelectBackward0>),\n",
       " 'T153': tensor([418.3273], grad_fn=<SelectBackward0>),\n",
       " 'T155': tensor([360.7118], grad_fn=<SelectBackward0>),\n",
       " 'T156': tensor([422.9428], grad_fn=<SelectBackward0>),\n",
       " 'T162': tensor([404.6867], grad_fn=<SelectBackward0>),\n",
       " 'T163': tensor([471.1531], grad_fn=<SelectBackward0>),\n",
       " 'T166': tensor([486.9422], grad_fn=<SelectBackward0>),\n",
       " 'T167': tensor([559.5049], grad_fn=<SelectBackward0>),\n",
       " 'T171': tensor([393.3252], grad_fn=<SelectBackward0>),\n",
       " 'T173': tensor([521.5304], grad_fn=<SelectBackward0>),\n",
       " 'T177': tensor([511.3131], grad_fn=<SelectBackward0>),\n",
       " 'T178': tensor([440.6003], grad_fn=<SelectBackward0>),\n",
       " 'T179': tensor([528.5776], grad_fn=<SelectBackward0>),\n",
       " 'T181': tensor([463.8166], grad_fn=<SelectBackward0>),\n",
       " 'T182': tensor([449.6337], grad_fn=<SelectBackward0>),\n",
       " 'T184': tensor([511.4629], grad_fn=<SelectBackward0>),\n",
       " 'T188': tensor([394.1333], grad_fn=<SelectBackward0>),\n",
       " 'T189': tensor([481.6390], grad_fn=<SelectBackward0>),\n",
       " 'T192': tensor([430.2803], grad_fn=<SelectBackward0>),\n",
       " 'T195': tensor([478.6248], grad_fn=<SelectBackward0>),\n",
       " 'T196': tensor([481.6390], grad_fn=<SelectBackward0>),\n",
       " 'T199': tensor([492.9427], grad_fn=<SelectBackward0>),\n",
       " 'T202': tensor([471.1531], grad_fn=<SelectBackward0>),\n",
       " 'T205': tensor([492.9427], grad_fn=<SelectBackward0>),\n",
       " 'T207': tensor([394.1333], grad_fn=<SelectBackward0>),\n",
       " 'T210': tensor([456.4621], grad_fn=<SelectBackward0>),\n",
       " 'T213': tensor([637.1786], grad_fn=<SelectBackward0>),\n",
       " 'T214': tensor([511.3131], grad_fn=<SelectBackward0>),\n",
       " 'T218': tensor([486.9422], grad_fn=<SelectBackward0>),\n",
       " 'T219': tensor([481.6390], grad_fn=<SelectBackward0>),\n",
       " 'T221': tensor([506.2199], grad_fn=<SelectBackward0>),\n",
       " 'T222': tensor([449.2634], grad_fn=<SelectBackward0>),\n",
       " 'T224': tensor([782.7525], grad_fn=<SelectBackward0>),\n",
       " 'T225': tensor([435.5368], grad_fn=<SelectBackward0>),\n",
       " 'T226': tensor([423.1187], grad_fn=<SelectBackward0>),\n",
       " 'T227': tensor([559.5049], grad_fn=<SelectBackward0>),\n",
       " 'T232': tensor([511.4629], grad_fn=<SelectBackward0>),\n",
       " 'T233': tensor([431.4900], grad_fn=<SelectBackward0>),\n",
       " 'T236': tensor([425.8077], grad_fn=<SelectBackward0>),\n",
       " 'T238': tensor([425.8077], grad_fn=<SelectBackward0>),\n",
       " 'T247': tensor([405.3950], grad_fn=<SelectBackward0>),\n",
       " 'T250': tensor([470.4631], grad_fn=<SelectBackward0>),\n",
       " 'T254': tensor([425.8077], grad_fn=<SelectBackward0>),\n",
       " 'T257': tensor([367.6985], grad_fn=<SelectBackward0>),\n",
       " 'T258': tensor([461.3387], grad_fn=<SelectBackward0>),\n",
       " 'T262': tensor([367.6985], grad_fn=<SelectBackward0>),\n",
       " 'T273': tensor([367.6985], grad_fn=<SelectBackward0>),\n",
       " 'T281': tensor([430.7205], grad_fn=<SelectBackward0>),\n",
       " 'T283': tensor([421.0535], grad_fn=<SelectBackward0>),\n",
       " 'T284': tensor([367.6985], grad_fn=<SelectBackward0>),\n",
       " 'T291': tensor([367.6985], grad_fn=<SelectBackward0>),\n",
       " 'T298': tensor([466.8665], grad_fn=<SelectBackward0>),\n",
       " 'T303': tensor([489.0047], grad_fn=<SelectBackward0>),\n",
       " 'T305': tensor([442.3930], grad_fn=<SelectBackward0>),\n",
       " 'T318': tensor([557.7968], grad_fn=<SelectBackward0>),\n",
       " 'T324': tensor([442.3930], grad_fn=<SelectBackward0>),\n",
       " 'T12': tensor([473.6336], grad_fn=<SelectBackward0>),\n",
       " 'T13': tensor([444.0182], grad_fn=<SelectBackward0>),\n",
       " 'T14': tensor([805.7698], grad_fn=<SelectBackward0>),\n",
       " 'T15': tensor([981.7546], grad_fn=<SelectBackward0>),\n",
       " 'T16': tensor([939.4517], grad_fn=<SelectBackward0>),\n",
       " 'T17': tensor([562.8135], grad_fn=<SelectBackward0>),\n",
       " 'T18': tensor([1041.3811], grad_fn=<SelectBackward0>),\n",
       " 'T20': tensor([594.1651], grad_fn=<SelectBackward0>),\n",
       " 'T33': tensor([701.3056], grad_fn=<SelectBackward0>),\n",
       " 'T34': tensor([832.1467], grad_fn=<SelectBackward0>),\n",
       " 'T35': tensor([1156.2302], grad_fn=<SelectBackward0>),\n",
       " 'T36': tensor([996.4789], grad_fn=<SelectBackward0>),\n",
       " 'T42': tensor([958.1601], grad_fn=<SelectBackward0>),\n",
       " 'T43': tensor([955.3121], grad_fn=<SelectBackward0>),\n",
       " 'T47': tensor([1306.8267], grad_fn=<SelectBackward0>),\n",
       " 'T48': tensor([517.9076], grad_fn=<SelectBackward0>),\n",
       " 'T59': tensor([390.5889], grad_fn=<SelectBackward0>),\n",
       " 'T62': tensor([486.9034], grad_fn=<SelectBackward0>),\n",
       " 'T63': tensor([214.8656], grad_fn=<SelectBackward0>),\n",
       " 'T69': tensor([945.8228], grad_fn=<SelectBackward0>),\n",
       " 'T71': tensor([918.4225], grad_fn=<SelectBackward0>),\n",
       " 'T72': tensor([722.3822], grad_fn=<SelectBackward0>),\n",
       " 'T74': tensor([567.7047], grad_fn=<SelectBackward0>),\n",
       " 'T76': tensor([646.8090], grad_fn=<SelectBackward0>),\n",
       " 'T78': tensor([543.5794], grad_fn=<SelectBackward0>),\n",
       " 'T79': tensor([764.6005], grad_fn=<SelectBackward0>),\n",
       " 'T80': tensor([690.5358], grad_fn=<SelectBackward0>),\n",
       " 'T87': tensor([562.1311], grad_fn=<SelectBackward0>),\n",
       " 'T88': tensor([513.7891], grad_fn=<SelectBackward0>),\n",
       " 'T93': tensor([812.1224], grad_fn=<SelectBackward0>),\n",
       " 'T94': tensor([690.2174], grad_fn=<SelectBackward0>),\n",
       " 'T98': tensor([932.5578], grad_fn=<SelectBackward0>),\n",
       " 'T102': tensor([462.4568], grad_fn=<SelectBackward0>),\n",
       " 'T107': tensor([662.7527], grad_fn=<SelectBackward0>),\n",
       " 'T121': tensor([548.5494], grad_fn=<SelectBackward0>),\n",
       " 'T124': tensor([760.7187], grad_fn=<SelectBackward0>),\n",
       " 'T131': tensor([651.6415], grad_fn=<SelectBackward0>),\n",
       " 'T132': tensor([898.2578], grad_fn=<SelectBackward0>),\n",
       " 'T134': tensor([627.0347], grad_fn=<SelectBackward0>),\n",
       " 'T138': tensor([574.2125], grad_fn=<SelectBackward0>),\n",
       " 'T139': tensor([561.0577], grad_fn=<SelectBackward0>),\n",
       " 'T140': tensor([536.8492], grad_fn=<SelectBackward0>),\n",
       " 'T141': tensor([641.5284], grad_fn=<SelectBackward0>),\n",
       " 'T146': tensor([633.1748], grad_fn=<SelectBackward0>),\n",
       " 'T154': tensor([782.4356], grad_fn=<SelectBackward0>),\n",
       " 'T159': tensor([827.5961], grad_fn=<SelectBackward0>),\n",
       " 'T161': tensor([875.1087], grad_fn=<SelectBackward0>),\n",
       " 'T169': tensor([256.0168], grad_fn=<SelectBackward0>),\n",
       " 'T174': tensor([950.2595], grad_fn=<SelectBackward0>),\n",
       " 'T176': tensor([1390.7440], grad_fn=<SelectBackward0>),\n",
       " 'T180': tensor([928.8557], grad_fn=<SelectBackward0>),\n",
       " 'T183': tensor([771.0026], grad_fn=<SelectBackward0>),\n",
       " 'T191': tensor([728.7630], grad_fn=<SelectBackward0>),\n",
       " 'T193': tensor([770.7186], grad_fn=<SelectBackward0>),\n",
       " 'T197': tensor([678.8159], grad_fn=<SelectBackward0>),\n",
       " 'T201': tensor([978.9465], grad_fn=<SelectBackward0>),\n",
       " 'T203': tensor([809.6446], grad_fn=<SelectBackward0>),\n",
       " 'T204': tensor([982.8010], grad_fn=<SelectBackward0>),\n",
       " 'T206': tensor([794.6099], grad_fn=<SelectBackward0>),\n",
       " 'T208': tensor([732.4052], grad_fn=<SelectBackward0>),\n",
       " 'T211': tensor([746.3749], grad_fn=<SelectBackward0>),\n",
       " 'T212': tensor([676.4361], grad_fn=<SelectBackward0>),\n",
       " 'T217': tensor([935.1911], grad_fn=<SelectBackward0>),\n",
       " 'T220': tensor([861.0908], grad_fn=<SelectBackward0>),\n",
       " 'T228': tensor([950.7470], grad_fn=<SelectBackward0>),\n",
       " 'T229': tensor([646.0320], grad_fn=<SelectBackward0>),\n",
       " 'T231': tensor([928.6713], grad_fn=<SelectBackward0>),\n",
       " 'T234': tensor([579.8150], grad_fn=<SelectBackward0>),\n",
       " 'T237': tensor([489.1041], grad_fn=<SelectBackward0>),\n",
       " 'T239': tensor([753.2575], grad_fn=<SelectBackward0>),\n",
       " 'T240': tensor([458.4746], grad_fn=<SelectBackward0>),\n",
       " 'T241': tensor([774.9063], grad_fn=<SelectBackward0>),\n",
       " 'T242': tensor([572.0508], grad_fn=<SelectBackward0>),\n",
       " 'T243': tensor([457.2476], grad_fn=<SelectBackward0>),\n",
       " 'T244': tensor([560.5760], grad_fn=<SelectBackward0>),\n",
       " 'T245': tensor([560.9542], grad_fn=<SelectBackward0>),\n",
       " 'T246': tensor([427.9100], grad_fn=<SelectBackward0>),\n",
       " 'T248': tensor([567.0036], grad_fn=<SelectBackward0>),\n",
       " 'T249': tensor([608.9535], grad_fn=<SelectBackward0>),\n",
       " 'T252': tensor([876.0636], grad_fn=<SelectBackward0>),\n",
       " 'T253': tensor([475.4672], grad_fn=<SelectBackward0>),\n",
       " 'T255': tensor([472.4257], grad_fn=<SelectBackward0>),\n",
       " 'T256': tensor([518.2025], grad_fn=<SelectBackward0>),\n",
       " 'T259': tensor([803.1905], grad_fn=<SelectBackward0>),\n",
       " 'T261': tensor([530.0137], grad_fn=<SelectBackward0>),\n",
       " 'T263': tensor([604.4147], grad_fn=<SelectBackward0>),\n",
       " 'T264': tensor([390.3373], grad_fn=<SelectBackward0>),\n",
       " 'T265': tensor([567.7470], grad_fn=<SelectBackward0>),\n",
       " 'T266': tensor([533.2081], grad_fn=<SelectBackward0>),\n",
       " 'T267': tensor([444.1831], grad_fn=<SelectBackward0>),\n",
       " 'T268': tensor([431.6903], grad_fn=<SelectBackward0>),\n",
       " 'T269': tensor([443.4044], grad_fn=<SelectBackward0>),\n",
       " 'T270': tensor([500.8601], grad_fn=<SelectBackward0>),\n",
       " 'T271': tensor([523.5820], grad_fn=<SelectBackward0>),\n",
       " 'T272': tensor([652.8914], grad_fn=<SelectBackward0>),\n",
       " 'T274': tensor([95.2691], grad_fn=<SelectBackward0>),\n",
       " 'T275': tensor([422.7152], grad_fn=<SelectBackward0>),\n",
       " 'T276': tensor([521.1817], grad_fn=<SelectBackward0>),\n",
       " 'T277': tensor([446.0547], grad_fn=<SelectBackward0>),\n",
       " 'T278': tensor([401.4392], grad_fn=<SelectBackward0>),\n",
       " 'T279': tensor([528.3116], grad_fn=<SelectBackward0>),\n",
       " 'T280': tensor([588.0428], grad_fn=<SelectBackward0>),\n",
       " 'T282': tensor([561.8879], grad_fn=<SelectBackward0>),\n",
       " 'T285': tensor([378.7888], grad_fn=<SelectBackward0>),\n",
       " 'T286': tensor([501.7172], grad_fn=<SelectBackward0>),\n",
       " 'T287': tensor([564.4361], grad_fn=<SelectBackward0>),\n",
       " 'T288': tensor([844.1671], grad_fn=<SelectBackward0>),\n",
       " 'T289': tensor([796.0877], grad_fn=<SelectBackward0>),\n",
       " 'T290': tensor([556.9391], grad_fn=<SelectBackward0>),\n",
       " 'T292': tensor([749.2304], grad_fn=<SelectBackward0>),\n",
       " 'T294': tensor([761.7175], grad_fn=<SelectBackward0>),\n",
       " 'T295': tensor([699.6948], grad_fn=<SelectBackward0>),\n",
       " 'T296': tensor([601.9711], grad_fn=<SelectBackward0>),\n",
       " 'T297': tensor([517.0832], grad_fn=<SelectBackward0>),\n",
       " 'T299': tensor([555.9565], grad_fn=<SelectBackward0>),\n",
       " 'T301': tensor([556.4568], grad_fn=<SelectBackward0>),\n",
       " 'T306': tensor([691.0712], grad_fn=<SelectBackward0>),\n",
       " 'T307': tensor([704.2155], grad_fn=<SelectBackward0>),\n",
       " 'T308': tensor([651.6070], grad_fn=<SelectBackward0>),\n",
       " 'T309': tensor([701.5524], grad_fn=<SelectBackward0>),\n",
       " 'T311': tensor([433.5328], grad_fn=<SelectBackward0>),\n",
       " 'T316': tensor([564.2191], grad_fn=<SelectBackward0>),\n",
       " 'T321': tensor([778.8627], grad_fn=<SelectBackward0>),\n",
       " 'T322': tensor([611.7899], grad_fn=<SelectBackward0>),\n",
       " 'T325': tensor([547.8959], grad_fn=<SelectBackward0>)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict = {}\n",
    "df_test_typeA = df_test[df_test[\"CALL_TYPE\"]==\"A\"]\n",
    "df_test_typeB = df_test[df_test[\"CALL_TYPE\"]==\"B\"]\n",
    "df_test_typeC = df_test[df_test[\"CALL_TYPE\"]==\"C\"]\n",
    "\n",
    "predictions_A = eval(call_type=\"A\", test_set=df_test_typeA, net=net_A)\n",
    "predictions_B = eval(call_type=\"B\", test_set=df_test_typeB, net=net_B)\n",
    "predictions_C = eval(call_type=\"C\", test_set=df_test_typeC, net=net_C)\n",
    "\n",
    "for idx in range(len(df_test_typeA)):\n",
    "    prediction_dict[df_test_typeA[\"TRIP_ID\"].iloc[idx]] = predictions_A[idx]\n",
    "    \n",
    "for idx in range(len(df_test_typeB)):\n",
    "    prediction_dict[df_test_typeB[\"TRIP_ID\"].iloc[idx]] = predictions_B[idx]\n",
    "    \n",
    "for idx in range(len(df_test_typeC)):\n",
    "    prediction_dict[df_test_typeC[\"TRIP_ID\"].iloc[idx]] = predictions_C[idx]\n",
    "\n",
    "prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "191b6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109411/4131001495.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample[\"TRAVEL_TIME\"].iloc[index] = predict.detach().squeeze().numpy()\n"
     ]
    }
   ],
   "source": [
    "# print(df_test)\n",
    "\n",
    "df_sample = pd.read_csv(\"../test/sampleSubmission.csv\")\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    predict = prediction_dict[row[\"TRIP_ID\"]]\n",
    "    df_sample[\"TRAVEL_TIME\"].iloc[index] = predict.detach().squeeze().numpy()\n",
    "#     if row[\"CALL_TYPE\"] == \"A\":\n",
    "#         predict = eval(call_type=\"A\", test_set=row, net = net_A)\n",
    "#         print(row[\"TRIP_ID\"] ,predict.detach().squeeze().numpy())\n",
    "#         predict_features = row[['Unique_TAXI_ID', 'ORIGIN_CALL', 'HR_0', 'HR_1', 'HR_10', 'HR_11', 'HR_12', 'HR_13', 'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_2', 'HR_20', 'HR_21', 'HR_22', 'HR_23', 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7', 'HR_8', 'HR_9']]\n",
    "#         test_features = torch.tensor(predict_features, dtype=torch.float)\n",
    "#         predict = eval(call_type=\"A\", test_set=test_features, net = net_A)net_A(test_features)\n",
    "#         print(row[\"TRIP_ID\"] ,predict.detach().squeeze().numpy())\n",
    "#         df_sample[\"TRAVEL_TIME\"].iloc[index] = predict.detach().squeeze().numpy()\n",
    "#     elif row[\"CALL_TYPE\"] == \"B\":\n",
    "#         predict_features = row[['Unique_TAXI_ID', 'ORIGIN_STAND', 'MON_1', 'MON_10', \n",
    "#                                 'MON_11', 'MON_12', 'MON_2', 'MON_3', 'MON_4', 'MON_5', \n",
    "#                                 'MON_6', 'MON_7', 'MON_8', 'MON_9', 'WK_0', 'WK_1', 'WK_2', \n",
    "#                                 'WK_3', 'WK_4', 'WK_5', 'WK_6', 'HR_0', 'HR_1', 'HR_10', \n",
    "#                                 'HR_11', 'HR_12', 'HR_13', 'HR_14', 'HR_15', 'HR_16', \n",
    "#                                 'HR_17', 'HR_18', 'HR_19', 'HR_2', 'HR_20', 'HR_21', \n",
    "#                                 'HR_22', 'HR_23', 'HR_3', 'HR_4', 'HR_5', 'HR_6', \n",
    "#                                 'HR_7', 'HR_8', 'HR_9']]\n",
    "#         test_features = torch.tensor(predict_features, dtype=torch.float)\n",
    "#         predict = net_B(test_features)\n",
    "#         print(row[\"TRIP_ID\"] ,predict.detach().squeeze().numpy())\n",
    "#         df_sample[\"TRAVEL_TIME\"].iloc[index] = predict.detach().squeeze().numpy()\n",
    "#     elif row[\"CALL_TYPE\"] == \"C\":\n",
    "#         predict_features = row[['Unique_TAXI_ID', 'MON_1', 'MON_10', 'MON_11', 'MON_12', \n",
    "#                                 'MON_2', 'MON_3', 'MON_4', 'MON_5', 'MON_6', 'MON_7', \n",
    "#                                 'MON_8', 'MON_9', 'WK_0', 'WK_1', 'WK_2', 'WK_3', 'WK_4', \n",
    "#                                 'WK_5', 'WK_6', 'HR_0', 'HR_1', 'HR_10', 'HR_11', 'HR_12', \n",
    "#                                 'HR_13', 'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', \n",
    "#                                 'HR_19', 'HR_2', 'HR_20', 'HR_21', 'HR_22', 'HR_23', \n",
    "#                                 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7', 'HR_8', 'HR_9']]\n",
    "#         test_features = torch.tensor(predict_features, dtype=torch.float)\n",
    "#         predict = net_C(test_features)\n",
    "#         print(row[\"TRIP_ID\"] ,predict.detach().squeeze().numpy())\n",
    "#         df_sample[\"TRAVEL_TIME\"].iloc[index] = predict.detach().squeeze().numpy()\n",
    "\n",
    "# test_features = torch.tensor(df_test.values, dtype=torch.float)\n",
    "\n",
    "# predict = net(val_features)\n",
    "# predict = predict.detach().squeeze().numpy()\n",
    "# print(predict[:1000])\n",
    "\n",
    "df_sample.to_csv(\"my_pred.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5325ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over every single \n",
    "def polyline_to_trip_duration(polyline):\n",
    "  return max(polyline.count(\"[\") - 1, 0) * 15\n",
    "\n",
    "# This code creates a new column, \"LEN\", in our dataframe. The value is\n",
    "# the (polyline_length - 1) * 15\n",
    "df_tr_test = pd.read_csv(\"../test/test.csv\")\n",
    "df_tr_test.head()\n",
    "\n",
    "df_tr_test[\"LEN\"] = df_tr_test[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "df_tr_test[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_tr_test[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85acca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictttt = df_sample[\"TRAVEL_TIME\"]\n",
    "reallllll = df_tr_test[\"LEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0dd186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real loss is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "980.5013400045522"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def custom_score(y_true, y_pred):\n",
    "#     rmse = mean_squared_error(np.log1p(y_true), np.log1p(y_pred), squared=False)\n",
    "#     return rmse\n",
    "    return math.sqrt(np.mean((np.array(y_pred)-np.array(y_true))*(np.array(y_pred)-np.array(y_true))))\n",
    "\n",
    "print(\"The real loss is :\")\n",
    "custom_score(reallllll,predictttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e98aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_test = pd.read_csv(\"../test/test.csv\")\n",
    "df_tr_test = df_tr_test.drop(columns=['POLYLINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a48f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../test/test_public.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c27005d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAH\n"
     ]
    }
   ],
   "source": [
    "if df_tr_test.equals(df_test):\n",
    "    print(\"YEAH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8b9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
